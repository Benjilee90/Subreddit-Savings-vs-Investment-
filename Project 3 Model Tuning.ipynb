{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Model Tuning and Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Organisation:\n",
    "1. Webscraping (SavingMoney & Investing)\n",
    "2. EDA and Preprocessing\n",
    "3. **Model Tuning and Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Library](#Libraries)\n",
    "- [Read CSV](#Read-CSV)\n",
    "- [Train-test Split](#Train-test-Split)\n",
    "- [Model Tuning](#Model-Tuning)\n",
    "- [Baseline Accuracy](#Baseline-Accuracy)\n",
    "- [NB & cvec](#Naive-Bayes-(Multinomial-NB)-and-CountVectorizer)\n",
    "- [NB & tvec](#Naive-Bayes-(Multinomial-NB)-and-TfidVectorizer)\n",
    "- [KNN & cvec](#K-Nearest-Neighbors-(KNN)-and-CountVectorizer)\n",
    "- [KNN & tvec](#K-Nearest-Neighbors-(KNN)-and-TfidVectorizer)\n",
    "- [LogReg & cvec](#Logistic-Regression-and-CountVectorizer)\n",
    "- [LogReg & tvec](#Logistic-Regression-and-TfidVectorizer)\n",
    "- [RF & cvec](#RandomForest-and-CountVectorizer)\n",
    "- [RF & cvec](#RandomForest-and-TfidVectorizer)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Model Insight](#Model-Insight)\n",
    "- [Conculsion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.read_csv('data/combine_reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be tested based on three features, the features are the title, the post, and the combination of title and post. This is to show how does each component affects the accuracy of the score.<br>\n",
    "To faciliate these process, Title will be known as Xt, Post will be known as Xp and the combined will be known as Xc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split based on title (Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>selftext_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>jth9il</td>\n",
       "      <td>Heads up: If you post a Yotta referral, I'm ju...</td>\n",
       "      <td>I just cleared out the mod queue and HOLY CRAP...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>head post yotta referral straight permabanning...</td>\n",
       "      <td>cleared mod queue holy crap jammed full spammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>k4tihv</td>\n",
       "      <td>Everything is Negotiable</td>\n",
       "      <td>Throughout my time working at a New York based...</td>\n",
       "      <td>3</td>\n",
       "      <td>925</td>\n",
       "      <td>everything negotiable</td>\n",
       "      <td>throughout time working new york based private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>k51oue</td>\n",
       "      <td>Best currency and saving bank account? (Advice...</td>\n",
       "      <td>I'm 20 and I never saved money for \"big projec...</td>\n",
       "      <td>11</td>\n",
       "      <td>119</td>\n",
       "      <td>best currency bank account advice begginer please</td>\n",
       "      <td>never money big project time spain currently l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>k3ejpc</td>\n",
       "      <td>Looking to switch my bank</td>\n",
       "      <td>Which bank is the most reasonable in terms of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>looking switch bank</td>\n",
       "      <td>bank reasonable term monthly payout fee benefi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>k2dbu9</td>\n",
       "      <td>An uncommon way to actually save money: improv...</td>\n",
       "      <td>I'm always trying to think smart, and while ev...</td>\n",
       "      <td>11</td>\n",
       "      <td>221</td>\n",
       "      <td>uncommon way actually money improve credit score</td>\n",
       "      <td>always trying think smart everyone going crazy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit      id                                              title  \\\n",
       "0          1  jth9il  Heads up: If you post a Yotta referral, I'm ju...   \n",
       "1          1  k4tihv                           Everything is Negotiable   \n",
       "2          1  k51oue  Best currency and saving bank account? (Advice...   \n",
       "3          1  k3ejpc                          Looking to switch my bank   \n",
       "4          1  k2dbu9  An uncommon way to actually save money: improv...   \n",
       "\n",
       "                                            selftext  title_len  text_len  \\\n",
       "0  I just cleared out the mod queue and HOLY CRAP...         17        16   \n",
       "1  Throughout my time working at a New York based...          3       925   \n",
       "2  I'm 20 and I never saved money for \"big projec...         11       119   \n",
       "3  Which bank is the most reasonable in terms of ...          5        15   \n",
       "4  I'm always trying to think smart, and while ev...         11       221   \n",
       "\n",
       "                                       title_cleaned  \\\n",
       "0  head post yotta referral straight permabanning...   \n",
       "1                              everything negotiable   \n",
       "2  best currency bank account advice begginer please   \n",
       "3                                looking switch bank   \n",
       "4   uncommon way actually money improve credit score   \n",
       "\n",
       "                                    selftext_cleaned  \n",
       "0    cleared mod queue holy crap jammed full spammer  \n",
       "1  throughout time working new york based private...  \n",
       "2  never money big project time spain currently l...  \n",
       "3  bank reasonable term monthly payout fee benefi...  \n",
       "4  always trying think smart everyone going crazy...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = combine['title_cleaned']\n",
    "y = combine['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_train, Xt_test, y_train, y_test = train_test_split(Xt, y,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((604,), (604,), (260,), (260,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_train.shape, y_train.shape, Xt_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split based on post (Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = combine['selftext_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_train, Xp_test, y_train, y_test = train_test_split(Xp, y,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((604,), (604,), (260,), (260,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp_train.shape, y_train.shape, Xp_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split based on title and post (Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine['titlepost'] = combine['title_cleaned'] + \" \" + combine['selftext_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = combine['titlepost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, y_train, y_test = train_test_split(Xp, y,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((604,), (604,), (260,), (260,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc_train.shape, y_train.shape, Xc_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy serves as score to compare against our model. In any case, the simplest model will give a 41% chance of classifying it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582176\n",
       "1    0.417824\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial NB) and CountVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Naive Bayes model, Tfid Vectorizer seems to score better when compare with the Count Vectorizer. This shows the the weightage of a word count when applied within Naive Bayes, it provides a higher accuracy as compared to using Count Vectorizer.\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "[Source](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "TfidfVectorizer and CountVectorizer both are methods for converting text data into vectors as model can process only numerical data. In CountVectorizer we only count the number of times a word appears in the document which results in biasing in favour of most frequent words. this ends up in ignoring rare words which could have helped is in processing our data more efficiently.In TfidfVectorizer we consider overall document weightage of a word. It helps us in dealing with most frequent words. Using it we can penalize them. TfidfVectorizer weights the word counts by a measure of how often they appear in the documents.\n",
    "[Source](https://www.quora.com/What-is-the-difference-between-TfidfVectorizer-and-CountVectorizer-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipe_cnb = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB())\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "params_cnb = {\n",
    "    'cvec__max_features': [2000, 3000, 4000],\n",
    "    'cvec__ngram_range':[(1,3)],\n",
    "    'cvec__min_df':[2,3],\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'nb__fit_prior': [True, False],\n",
    "    'nb__alpha': [0, 0.4, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsnb = GridSearchCV(pipe_cnb, \n",
    "                    param_grid = params_cnb,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsnb.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9089403973509934"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gsnb.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192307692307692"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsnb.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 131\n",
      "False Positives: 20\n",
      "False Negatives: 27\n",
      "True Positives: 82\n"
     ]
    }
   ],
   "source": [
    "pred = gsnb.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(cvec)[title]**: The accuracy for based on train and test is low despite with train being 90.89% while test bring 81.92%. With the train and test being almost 10% apart, the model is overfitted and should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsnb.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668874172185431"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gsnb.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461538461538461"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsnb.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 141\n",
      "False Positives: 10\n",
      "False Negatives: 4\n",
      "True Positives: 105\n"
     ]
    }
   ],
   "source": [
    "pred = gsnb.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(cvec)[post]**: The accuracy for based on train and test is high with train being 95.53% while test bring 93.84%. The score between train and test is quite close (~2% apart), this model can be considered to be selected but the accuracy is only 93.84% which means that it has still a 6.15% where the model is unable to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title & post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsnb.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668874172185431"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gsnb.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461538461538461"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsnb.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 141\n",
      "False Positives: 10\n",
      "False Negatives: 4\n",
      "True Positives: 105\n"
     ]
    }
   ],
   "source": [
    "pred = gsnb.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(cvec)[combine]**: The accuracy for based on train and test is high with train being 95.53% while test bring 93.84%. The score between train and test is quite close (~2% apart), this model can be considered to be selected but the accuracy is only 93.84% which means that it has still a 6.15% where the model is unable to predict.\n",
    "Note: the score is also similar to NB(cvec)[post]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial NB) and TfidVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipe_tnb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('nb', MultinomialNB())\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "params_tnb = {\n",
    "    'tvec__max_features': [2000, 3000, 4000],\n",
    "    'tvec__ngram_range':[(1,3)],\n",
    "    'tvec__min_df':[2,3],\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'nb__fit_prior': [True, False],\n",
    "    'nb__alpha': [0, 0.4, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gstnb = GridSearchCV(pipe_tnb, \n",
    "                    param_grid = params_tnb,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gstnb.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172185430463576"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gstnb.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115384615384615"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gstnb.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 129\n",
      "False Positives: 22\n",
      "False Negatives: 27\n",
      "True Positives: 82\n"
     ]
    }
   ],
   "source": [
    "pred = gstnb.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(tvec)[title]**: The accuracy for based on train and test is low despite with train being 91.72% while test bring 81.15%. With the train and test being almost 10% apart, the model is overfitted and should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   22.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gstnb.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867549668874173"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gstnb.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gstnb.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 144\n",
      "False Positives: 7\n",
      "False Negatives: 6\n",
      "True Positives: 103\n"
     ]
    }
   ],
   "source": [
    "pred = gstnb.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(tvec)[post]**: The accuracy for based on train and test is high with train being 98.68% while test bring 95%. The score between train and test is quite close (~3% apart), this model can be considered to be selected as it also has the best accuracy amongst all model. Based on the computing timing to fit the model, it also takes lesser time comparing with the second best mondel to NB(tvec)[combine]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'nb__alpha': [0, 0.4, 0.8],\n",
       "                         'nb__fit_prior': [True, False],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gstnb.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867549668874173"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gstnb.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gstnb.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 144\n",
      "False Positives: 7\n",
      "False Negatives: 6\n",
      "True Positives: 103\n"
     ]
    }
   ],
   "source": [
    "pred = gstnb.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for NB(tvec)[combine]**: The accuracy for based on train and test is high with train being 98.68% while test bring 95%. The score between train and test is quite close (~3% apart), this model can be considered to be selected as it also has the best accuracy amongst all model. However, when comparing computing timing to fit the model, it takes longer time comparing with NB(tvec)[post]. This is due to additional time required to compute both the title and post as one input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors (KNN) and CountVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While KNN is one of the model used in ML, in this scenario the models are overfitted and results of accuracy are low for test data. When using CountVectorizer, the test score is grossly overfitted when compared with the test data. However, it works differently for TdifVectorizer as the model is not overfitted for post and has one of highest accuracy when compared with other models.\n",
    "\n",
    "[Source](https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm)\n",
    "\n",
    "K-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm which can be used for both classification as well as regression predictive problems. However, it is mainly used for classification predictive problems in industry. The following two properties would define KNN well −\n",
    "- Lazy learning algorithm − KNN is a lazy learning algorithm because it does not have a specialized training phase and uses all the data for training while classification.\n",
    "- Non-parametric learning algorithm − KNN is also a non-parametric learning algorithm because it doesn’t assume anything about the underlying data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cknn = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors = 5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the params for KNN\n",
    "params_cknn = {\n",
    "    'knn__n_neighbors': range(1, 51, 10),\n",
    "    'knn__p': [1, 2],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "gs_cknn = GridSearchCV(pipe_cknn,\n",
    "                      param_grid=params_cknn,\n",
    "                      n_jobs = -1,\n",
    "                      cv=5,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cknn.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_cknn.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5615384615384615"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_cknn.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 40\n",
      "False Positives: 111\n",
      "False Negatives: 3\n",
      "True Positives: 106\n"
     ]
    }
   ],
   "source": [
    "pred = gs_cknn.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(cvec)[title]**: The model is serverly overfitted and should be avoided as the train and test is almost 45% apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cknn.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_cknn.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923076923076923"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_cknn.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 47\n",
      "False Positives: 104\n",
      "False Negatives: 2\n",
      "True Positives: 107\n"
     ]
    }
   ],
   "source": [
    "pred = gs_cknn.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(cvec)[post]**: The model is serverly overfitted and should be avoided as the train and test is almost 40 apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title & post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cknn.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_cknn.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923076923076923"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_cknn.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 47\n",
      "False Positives: 104\n",
      "False Negatives: 2\n",
      "True Positives: 107\n"
     ]
    }
   ],
   "source": [
    "pred = gs_cknn.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(cvec)[combine]**: The model is serverly overfitted and should be avoided as the train and test is almost 40 apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN and TfidVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipe_tknn = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors = 5))\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "params_tknn = {\n",
    "    'tvec__max_features': [2000, 3000, 4000],\n",
    "    'tvec__ngram_range':[(1,3)],\n",
    "    'tvec__min_df':[2,3],\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'knn__n_neighbors': range(1, 51, 10),\n",
    "    'knn__p': [1, 2],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "gs_tknn = GridSearchCV(pipe_tknn,\n",
    "                      param_grid=params_tknn,\n",
    "                      n_jobs = -1,\n",
    "                      cv=5,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tknn.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294701986754967"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_tknn.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730769230769231"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_tknn.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 117\n",
      "False Positives: 34\n",
      "False Negatives: 25\n",
      "True Positives: 84\n"
     ]
    }
   ],
   "source": [
    "pred = gs_tknn.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(tvec)[title]**: Despite TfidVectorizer increasing the accuracy of the KNN model as compared to cvec, the test accuracy is still relative low as compared to other models. Hence, this model should be avoided too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tknn.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_tknn.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384615384615385"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_tknn.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 142\n",
      "False Positives: 9\n",
      "False Negatives: 7\n",
      "True Positives: 102\n"
     ]
    }
   ],
   "source": [
    "pred = gs_tknn.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(tvec)[post]**: In this scenario, the TfidVectorizer increases the accuracy of the KNN model as compared to cvec, the test accuracy is also one of the best comparing with other model. However, this is still not the best accuracy when compared with NB(tvec)[post]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title & post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                         'knn__n_neighbors': range(1, 51, 10), 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tknn.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gs_tknn.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384615384615385"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gs_tknn.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 142\n",
      "False Positives: 9\n",
      "False Negatives: 7\n",
      "True Positives: 102\n"
     ]
    }
   ],
   "source": [
    "pred = gs_tknn.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for KNN(tvec)[combine]**: In this scenario, the TfidVectorizer increases the accuracy of the KNN model as compared to cvec, the test accuracy is also one of the best comparing with other model. However, this is still not the best accuracy when compared with NB(tvec)[post]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and CountVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression on avarage provided 90% accuracy for most of it model between the two vectorizer and features applied. However, the top accuracy is still lower when compared with Naive Bayes. Hence, this model was not selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipe_clr = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "params_clr = {\n",
    "    'cvec__max_features': [3000, 4000, 5000, 10000],\n",
    "    'cvec__ngram_range':[(1,3)],\n",
    "    'cvec__min_df':[2,3],\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'lr__max_iter': [1000],\n",
    "    'lr__penalty':['l2','l1'],\n",
    "    'lr__C':[0.1, 1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes GridSearch\n",
    "gslr = GridSearchCV(pipe_clr, \n",
    "                    param_grid = params_clr,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000, 10000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'lr__C': [0.1, 1, 10], 'lr__max_iter': [1000],\n",
       "                         'lr__penalty': ['l2', 'l1']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslr.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354304635761589"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data accuracy score\n",
    "gslr.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153846153846154"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gslr.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 137\n",
      "False Positives: 14\n",
      "False Negatives: 34\n",
      "True Positives: 75\n"
     ]
    }
   ],
   "source": [
    "pred = gslr.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(cvec)[title]**: The Logistic Regression Model on title indicates that the model is overfitted when comparing the train and test scoring. This model should be avoid for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   28.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000, 10000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'lr__C': [0.1, 1, 10], 'lr__max_iter': [1000],\n",
       "                         'lr__penalty': ['l2', 'l1']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslr.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917218543046358"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data accuracy score\n",
    "gslr.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gslr.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 136\n",
      "False Positives: 15\n",
      "False Negatives: 5\n",
      "True Positives: 104\n"
     ]
    }
   ],
   "source": [
    "pred = gslr.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(cvec)[post]**: The test accuracy is better comparing with title indicating post provides a better accuracy comparing with title. However, the accuracy is still lower when compared to NB(tvec)[post]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title & post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   29.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000, 10000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'lr__C': [0.1, 1, 10], 'lr__max_iter': [1000],\n",
       "                         'lr__penalty': ['l2', 'l1']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslr.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917218543046358"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data accuracy score\n",
    "gslr.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gslr.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 136\n",
      "False Positives: 15\n",
      "False Negatives: 5\n",
      "True Positives: 104\n"
     ]
    }
   ],
   "source": [
    "pred = gslr.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(cvec)[combine]**: The test accuracy is better comparing with title indicating post provides a better accuracy comparing with title. However, the accuracy is still lower when compared to NB(tvec)[post]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and TfidVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipeTlr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "paramsTlr = {\n",
    "    'tvec__max_features': [2000, 3000, 4000],\n",
    "    'tvec__ngram_range':[(1,3)],\n",
    "    'tvec__min_df':[2,3],\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'lr__penalty':['l2','l1'],\n",
    "    'lr__C':[0.1, 1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes GridSearch\n",
    "gsTlr = GridSearchCV(pipeTlr, \n",
    "                    param_grid = paramsTlr,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 1, 10], 'lr__penalty': ['l2', 'l1'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsTlr.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586092715231788"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gsTlr.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038461538461539"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsTlr.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 133\n",
      "False Positives: 18\n",
      "False Negatives: 33\n",
      "True Positives: 76\n"
     ]
    }
   ],
   "source": [
    "pred = gsTlr.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(tvec)[title]**: This model is overfitted with the train and test score being 15% apart and should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   20.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 1, 10], 'lr__penalty': ['l2', 'l1'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsTlr.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983443708609272"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "gsTlr.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9153846153846154"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsTlr.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 140\n",
      "False Positives: 11\n",
      "False Negatives: 11\n",
      "True Positives: 98\n"
     ]
    }
   ],
   "source": [
    "pred = gsTlr.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(tvec)[post]**: While the train score shows a very good accuracy scoring, the test scoring is not as good comparing with other models. There are also signs of overfitting with train and test being almost 10% apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   20.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 1, 10], 'lr__penalty': ['l2', 'l1'],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsTlr.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983443708609272"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsTlr.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9153846153846154"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "gsTlr.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 140\n",
      "False Positives: 11\n",
      "False Negatives: 11\n",
      "True Positives: 98\n"
     ]
    }
   ],
   "source": [
    "pred = gsTlr.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for LR(tvec)[combine]**: While the train score shows a very good accuracy scoring, the test scoring is not as good comparing with other models. There are also signs of overfitting with train and test being almost 10% apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest and CountVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While RandomForest tend to combat overfitting, the accuracy of the model is still lower when compared with other models.\n",
    "\n",
    "[Source](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "piperf = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "paramsrf = {\n",
    "    'cvec__max_features': [3000, 4000, 5000],\n",
    "    'cvec__ngram_range':[(1,3)],\n",
    "    'cvec__min_df':[2,3],\n",
    "    'cvec__max_df': [0.9, 0.95],\n",
    "    'rf__n_estimators': [100, 150, 200],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes GridSearch\n",
    "gsrf = GridSearchCV(piperf, \n",
    "                    param_grid = paramsrf,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:   50.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321192052980133"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7538461538461538"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 119\n",
      "False Positives: 32\n",
      "False Negatives: 32\n",
      "True Positives: 77\n"
     ]
    }
   ],
   "source": [
    "pred = gsrf.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(cvec)[title]**: Model is serverly overfitted with the train and test score being 20% apart. This model should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076923076923077"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 134\n",
      "False Positives: 17\n",
      "False Negatives: 7\n",
      "True Positives: 102\n"
     ]
    }
   ],
   "source": [
    "pred = gsrf.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(cvec)[post]**: The model score well in both train and test with train being 100% and test being 92.3%. This model is one of the best among the rest but it requires longer computing time when fitting and the accuracy score is still lower than a few of the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3], 'cvec__ngram_range': [(1, 3)],\n",
       "                         'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9153846153846154"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 135\n",
      "False Positives: 16\n",
      "False Negatives: 6\n",
      "True Positives: 103\n"
     ]
    }
   ],
   "source": [
    "pred = gsrf.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(cvec)[combine]**: Based on the cvec model of combine, the accuracy lowers as compared to the model with purely post. This may be due to the features selected in combine is doing poorer than the features selected in post. Hence, the overall accuracy is lower despite getting a perfect score in the train dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest and TfidVectorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates pipeline to handle vectorization and logistic regression steps\n",
    "pipe_trf = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "     ])\n",
    "\n",
    "#Specifies different hyperparameter values that we want to test across\n",
    "params_trf = {\n",
    "    'tvec__max_features': [2000, 3000, 4000],\n",
    "    'tvec__ngram_range':[(1,3)],\n",
    "    'tvec__min_df':[2,3],\n",
    "    'tvec__max_df': [0.9, 0.95],\n",
    "    'rf__n_estimators': [100, 150, 200],\n",
    "    'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes GridSearch\n",
    "gs_trf = GridSearchCV(pipe_trf, \n",
    "                    param_grid = params_trf,\n",
    "                    n_jobs = -1,\n",
    "                    cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:   52.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668874172185431"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846153846153846"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 115\n",
      "False Positives: 36\n",
      "False Negatives: 20\n",
      "True Positives: 89\n"
     ]
    }
   ],
   "source": [
    "pred = gs_trf.predict(Xt_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(tvec)[title]**: The model is serverly overfitted and should be avoided. As title itself does not seem to be a good feature to use, the scores are generally lower than post and combine. This may be due to limited data points within title as compare to post and combine. On top of that, this model is serverly overfitted with the scores almost 20% apart from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.fit(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115384615384615"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xp_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 134\n",
      "False Positives: 17\n",
      "False Negatives: 6\n",
      "True Positives: 103\n"
     ]
    }
   ],
   "source": [
    "pred = gs_trf.predict(Xp_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(tvec)[post]**: Comparing the model with cvec, the model with cvec scored better as compared to the model with tvec. This shows that the weight based on the frequency of the word(tvec) as compared to giving equal weightage(cvec) performed in an not ideal way for this case. The model is also overfitted with more than 10% apart despite the train score getting a perfect 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring based on title and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': [None, 1, 2, 3, 4, 5],\n",
       "                         'rf__n_estimators': [100, 150, 200],\n",
       "                         'tvec__max_df': [0.9, 0.95],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.fit(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115384615384615"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_trf.score(Xc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 134\n",
      "False Positives: 17\n",
      "False Negatives: 6\n",
      "True Positives: 103\n"
     ]
    }
   ],
   "source": [
    "pred = gs_trf.predict(Xc_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation for RF(tvec)[combine]**: Looking at four different models within Rf, there is a difference within cvec and tvec with the input from post and combine. While combine scored better using tvec, the post did better when using cvec. However, this may also be due to features selected by random forest which cost the accuracy to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all the models that were tested, the best model and feature with the highest accuracy is **Naive Bayes (Multinominal NB) with Tfid Vectorizer** with the highest accuracy of **95%** among all the models that have been tested. While some have a higher accuracy in the train model, the accuracy tells otherwise in the test set. This indicates that the model is overfitting and hence does not work well with new data set. <br>\n",
    "\n",
    "Among the features, the 'title' feature performed the worst in terms of accuracy while 'post' and 'combine' scored on par until it was past through the RandomForest Model. However, comparing the computing time based on the best model, using 'post' as the feature proves to require less computing time. Hence, 'post' is sufficient to be used as a prediction.<br>\n",
    "\n",
    "\n",
    "In summary, **NB with Tfid coupled with post** as the feature shows a better results among the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Comparison**\n",
    "\n",
    "|S/N|Model|Vectorizer|Feature|Train|Test|TN|FP|FN|TP\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "|1|Naive Bayes (Multinomial NB)|cvec|title|0.9089|0.8192|131|20|27|82|\n",
    "|2|Naive Bayes (Multinomial NB)|cvec|post|0.9669|0.9462|141|10|4|105|\n",
    "|3|Naive Bayes (Multinomial NB)|cvec|combine|0.9669|0.9462|141|10|4|105|\n",
    "|4|Naive Bayes (Multinomial NB)|tvec|title|0.9172|0.8115|129|22|27|82|\n",
    "|**5**|**Naive Bayes (Multinomial NB)**|**tvec**|**post**|**0.9867**|**0.95**|**144**|**7**|**6**|**103**|\n",
    "|6|Naive Bayes (Multinomial NB)|tvec|combine|0.9867|0.95|144|7|6|103|\n",
    "|7|K Nearest Neighbors (KNN)|cvec|title|1.0|0.5615|40|111|3|106\n",
    "|8|K Nearest Neighbors (KNN)|cvec|post|1.0|0.5923|47|104|2|107|\n",
    "|9|K Nearest Neighbors (KNN)|cvec|combine|1.0|0.5923|47|104|2|107|\n",
    "|10|K Nearest Neighbors (KNN)|tvec|title|0.8294|0.7730|117|34|25|84|\n",
    "|11|K Nearest Neighbors (KNN)|tvec|post|1.0|0.9346|142|9|7|102|\n",
    "|12|K Nearest Neighbors (KNN)|tvec|combine|1.0|0.9346|142|9|7|102|\n",
    "|13|Logistic Regression (LR)|cvec|title|0.9354|0.8153|137|14|34|75|\n",
    "|14|Logistic Regression (LR)|cvec|post|0.9933|0.9230|136|15|5|104|\n",
    "|15|Logistic Regression (LR)|cvec|combine|0.9933|0.9230|136|15|5|104|\n",
    "|16|Logistic Regression (LR)|tvec|title|0.9586|0.8038|133|18|33|76|\n",
    "|17|Logistic Regression (LR)|tvec|post|0.9983|0.9153|140|11|11|98|\n",
    "|18|Logistic Regression (LR)|tvec|combine|0.9983|0.9153|140|11|11|98|\n",
    "|19|Random Forest (RF)|cvec|title|0.9668|0.7615|119|32|32|77|\n",
    "|20|Random Forest (RF)|cvec|post|1.0|0.9230|134|17|7|102|\n",
    "|21|Random Forest (RF)|cvec|combine|1.0|0.8923|135|16|6|103|\n",
    "|22|Random Forest (RF)|tvec|title|0.9668|0.7807|115|36|20|89|\n",
    "|23|Random Forest (RF)|tvec|post|1.0|0.8961|134|17|6|103|\n",
    "|24|Random Forest (RF)|tvec|combine|1.0|0.9153|134|17|6|103|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Insight\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the best model, we look into the top 10 most correlated words(s) for each of the subreddit. As the investment terminology are quite distinct from saving, term like liquidity have a stronger correlation with investment. While for savings, money and account have a strong correlation. <br>\n",
    "\n",
    "Apart from highly correlated words, there are other words like thank, month and week which are considered misclassified words and should be removed in order to increase the accuracy of the model. This will result in false prediction due to misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(gstnb.best_estimator_.steps[1][1].coef_).T\n",
    "coefs.columns = ['coef']\n",
    "coefs['ngram'] = gstnb.best_estimator_.steps[0][1].get_feature_names()\n",
    "coefs = coefs[['ngram','coef']]\n",
    "coefs = coefs.sort_values('coef', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_investment_coefs = coefs.tail(15).sort_values(by='coef', ascending=False).reset_index(drop=True)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_investment_coefs, x=-top_investment_coefs['coef'], y='ngram')\n",
    "plt.ylabel('')\n",
    "plt.title('Top 10 Correlated word(s) with r/SavingMoney', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_saving_coefs = coefs.head(15).reset_index(drop=True)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data=top_saving_coefs, x=-top_saving_coefs['coef'], y='ngram')\n",
    "plt.ylabel('')\n",
    "plt.title('Top 10 Correlated word(s) with r/Investing', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.992489</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>context appulse corp centrifuge manufacturing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.991243</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>palantir technology inc posted best week since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.989508</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>hello decided would comparable analysis major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.988205</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>wall street bracing tesla inc nasdaq tsla arri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.987977</td>\n",
       "      <td>0.012023</td>\n",
       "      <td>hello want highlight point observed market pas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1                                               text\n",
       "515  0.992489  0.007511  context appulse corp centrifuge manufacturing ...\n",
       "454  0.991243  0.008757  palantir technology inc posted best week since...\n",
       "673  0.989508  0.010492  hello decided would comparable analysis major ...\n",
       "453  0.988205  0.011795  wall street bracing tesla inc nasdaq tsla arri...\n",
       "368  0.987977  0.012023  hello want highlight point observed market pas..."
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Puts probabilities and text into a dataframe\n",
    "pred = pd.DataFrame(gstnb.predict_proba(Xp))\n",
    "pred['text'] = combine['selftext_cleaned']\n",
    "\n",
    "#Shows the top predicted comments\n",
    "pred.sort_values(1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.984824</td>\n",
       "      <td>student working part time job retail really ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.986435</td>\n",
       "      <td>recently found app called getupside let certai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.987762</td>\n",
       "      <td>hi everyone decent paying job area reasonable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.988793</td>\n",
       "      <td>anything like average human looking bank accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.008435</td>\n",
       "      <td>0.991565</td>\n",
       "      <td>half income one salary requires discipline pos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1                                               text\n",
       "251  0.015176  0.984824  student working part time job retail really ba...\n",
       "308  0.013565  0.986435  recently found app called getupside let certai...\n",
       "45   0.012238  0.987762  hi everyone decent paying job area reasonable ...\n",
       "77   0.011207  0.988793  anything like average human looking bank accou...\n",
       "188  0.008435  0.991565  half income one salary requires discipline pos..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows the top predicted comments\n",
    "pred.sort_values(1).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, both subreddit(r/investing & r/SavingMoney) are quite distinct from one another as the average accuracy of the model ranges from 50 to 90% with the highest being 95%. While both revolves around money, the way in which how the money is utilized is different. Hence, the correlated words used in the prediction is not highly correlated between post as shown in the EDA process. \n",
    "\n",
    "During the model selection, the Naive Bayes and TdifVectorizer model is able predict with an accuracy of 95% based on the testing data and 98.6% based on the training. Among all the features, between title, post and combining both, post seems to give the best results in terms of accuracy and computing time. While combing both title and post may increase the accruary, it is limited with the max number of features allowed to pass through the model and requires longer computing time. Among all the model, it proves to be the best as it is not overfitted and has the highest accuracy for test data when identifying saving related post as tasked by our client.\n",
    "\n",
    "However, the model has some limitation. Currently, there are some misclassified words within the model which will throw the prediction off if the words appears within a post that may not be savings related. The words should be removed to increase the accuracy of the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.306px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
